(window.webpackJsonp=window.webpackJsonp||[]).push([[13],{403:function(v,r,_){"use strict";_.r(r);var t=_(2),a=Object(t.a)({},(function(){var v=this,r=v._self._c;return r("ContentSlotsDistributor",{attrs:{"slot-key":v.$parent.slotKey}},[r("h1",{attrs:{id:"目录"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#目录"}},[v._v("#")]),v._v(" 目录")]),v._v(" "),r("ul",[r("li",[r("a",{attrs:{href:"#%E6%A6%82%E8%BF%B0"}},[v._v("概述")])]),v._v(" "),r("li",[r("a",{attrs:{href:"#level-1-%E5%9C%A8%E7%BA%BF%E9%A2%84%E6%B5%8B-%E4%BD%A0%E7%9A%84%E7%B3%BB%E7%BB%9F%E5%8F%AF%E4%BB%A5%E5%AE%9E%E6%97%B6%E8%BF%9B%E8%A1%8C%E9%A2%84%E6%B5%8B"}},[v._v("level 1：在线预测——你的系统可以实时进行预测")]),v._v(" "),r("ul",[r("li",[r("a",{attrs:{href:"#%E5%BA%94%E7%94%A8%E6%A1%88%E4%BE%8B"}},[v._v("应用案例")])]),v._v(" "),r("li",[r("a",{attrs:{href:"#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"}},[v._v("解决方案")])])])]),v._v(" "),r("li",[r("a",{attrs:{href:"#level-2-%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0-%E4%BD%A0%E7%9A%84%E7%B3%BB%E7%BB%9F%E5%8F%AF%E4%BB%A5%E6%8E%A5%E6%94%B6%E6%96%B0%E6%95%B0%E6%8D%AE%E5%B9%B6%E5%AE%9E%E6%97%B6%E6%9B%B4%E6%96%B0"}},[v._v("level 2：持续学习——你的系统可以接收新数据并实时更新")]),v._v(" "),r("ul",[r("li",[r("a",{attrs:{href:"#%E5%BA%94%E7%94%A8%E6%A1%88%E4%BE%8B"}},[v._v("应用案例")])]),v._v(" "),r("li",[r("a",{attrs:{href:"#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"}},[v._v("解决方案")])]),v._v(" "),r("li",[r("a",{attrs:{href:"#%E6%8C%91%E6%88%98"}},[v._v("挑战")])])])]),v._v(" "),r("li",[r("a",{attrs:{href:"#%E6%80%BB%E7%BB%93"}},[v._v("总结")])])]),v._v(" "),r("h2",{attrs:{id:"概述"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#概述"}},[v._v("#")]),v._v(" 概述")]),v._v(" "),r("p",[v._v("我注意到当前业界在ML应用方面存在两组公司。一组已经对基础设施进行了大量投资（数亿元），以实现实时ML，并且已经看到了投资的回报；另一组公司仍然怀疑实时ML是否有价值。")]),v._v(" "),r("p",[v._v("在前几年，对于实时ML的含义，似乎没有什么共识，而且业界也没有对它的做法进行深入讨论。在这篇文章中，我想分享我当前业界在实时ML方向的发展状况。")]),v._v(" "),r("p",[v._v("实时ML是使用实时数据来产生更准确的预测，并使模型适应不断变化的环境的方法。实时ML有两个level，我将在这篇文章中进行介绍。")]),v._v(" "),r("ul",[r("li",[v._v("level 1：你的ML系统实时进行预测（在线预测）。")]),v._v(" "),r("li",[v._v("level 2：你的系统可以纳入新的数据并实时更新你的模型（持续学习）。\n我用“模型”来指机器学习模型，用“系统”来指它周围的基础设施，包括数据管道和监控系统。")])]),v._v(" "),r("h2",{attrs:{id:"level-1-在线预测-你的系统可以实时进行预测"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#level-1-在线预测-你的系统可以实时进行预测"}},[v._v("#")]),v._v(" level 1：在线预测——你的系统可以实时进行预测")]),v._v(" "),r("p",[v._v("这里的实时定义为在毫秒到秒的范围内。")]),v._v(" "),r("h3",{attrs:{id:"应用案例"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#应用案例"}},[v._v("#")]),v._v(" 应用案例")]),v._v(" "),r("p",[v._v("延迟很重要，特别是对于面向用户的应用程序。2009年，"),r("a",{attrs:{href:"https://services.google.com/fh/files/blogs/google_delayexp.pdf",target:"_blank",rel:"noopener noreferrer"}},[v._v("谷歌的实验表明，网络搜索延迟增加100至400毫秒，每个用户每天的搜索次数减少0.2%至0.6%"),r("OutboundLink")],1),v._v("。2019年，"),r("a",{attrs:{href:"https://blog.acolyer.org/2019/10/07/150-successful-machine-learning-models/",target:"_blank",rel:"noopener noreferrer"}},[v._v("Booking.com发现，延迟增加30%，就会损失约0.5%的转化率——“对我们的业务来说是一个延迟与成本是正相关的”"),r("OutboundLink")],1),v._v("。")]),v._v(" "),r("p",[v._v("无论你的ML模型有多棒，如果它们在进行预测时需要几百毫秒甚至秒级的时间，用户就会点击其他东西。")]),v._v(" "),r("h4",{attrs:{id:"批量预测的问题"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#批量预测的问题"}},[v._v("#")]),v._v(" 批量预测的问题")]),v._v(" "),r("p",[v._v("在业界离线预测也是比较普遍的存在，即离线情况下批量生成预测结果，将其存储起来（例如在SQL表中），并在需要时拉出预先计算的预测结果。")]),v._v(" "),r("p",[v._v("当输入空间是有限的时候，这就可以发挥作用--你需要确切地知道有多少可能的输入要进行预测。一个例子是当你需要为你的用户生成电影推荐时--你确切地知道有多少用户。所以你定期为每个用户预测一组推荐，比如每隔几个小时。")]),v._v(" "),r("p",[v._v("为了使他们的用户输入空间有限，许多应用程序让他们的用户从类别中选择，而不是胡乱输入查询。例如，如果你到大众点评上点餐，你首先要进行定位，或者指定的一个具体位置。这种方法有很多局限性。当然，其结果在其预定义的类别中还不错，如 “航空科技大厦”附近的“餐馆”，但当你试图输入“北京的高评级鲁菜餐馆”这样的无目标的查询时，结果就可能不太理想。")]),v._v(" "),r("p",[v._v("批量预测造成的限制甚至存在于像Netflix这样技术上更先进的公司。比如说，你最近看了很多恐怖片，所以当你第一次登录Netflix时，恐怖片在推荐中占主导地位。但你今天感觉很兴奋，所以你搜索了“喜剧”并开始浏览喜剧类别。Netflix应该学习并在你的推荐列表中向你展示更多喜剧，对吗？但它不能更新列表，而是要直到下一次生成批量推荐。")]),v._v(" "),r("p",[v._v("在上面的两个例子中，批量预测导致了用户体验的下降（这与用户活跃度/留存紧密相连），而不是灾难性的失败。其他例子还有广告排名、微博的趋势标签排名、滴滴预估匹配时间等。")]),v._v(" "),r("p",[v._v("从批量预测转换到实时预测，可以使用动态特征来进行更相关的预测。这里的静态特征指的是变化缓慢或很少变化的信息，如年龄、性别、工作、好友圈等。动态特征是基于现在正在发生的事件的特征，比如你正在浏览什么，你刚刚下单了什么等等。了解用户当前的兴趣，将使你的系统能够做出与他们更相关的推荐。")]),v._v(" "),r("h3",{attrs:{id:"解决方案"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#解决方案"}},[v._v("#")]),v._v(" 解决方案")]),v._v(" "),r("p",[v._v("为了使你的系统能够进行在线预测，它必须有两个组成部分：")]),v._v(" "),r("ul",[r("li",[v._v("快速推理：可以在几毫秒内做出预测的模型。")]),v._v(" "),r("li",[v._v("实时管道：能够处理数据，将其输入模型，并实时返回预测的管道。")])]),v._v(" "),r("h4",{attrs:{id:"快速推理"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#快速推理"}},[v._v("#")]),v._v(" 快速推理")]),v._v(" "),r("p",[v._v("当一个模型太大，预测时间太长时，有三种方法：")]),v._v(" "),r("ol",[r("li",[v._v("使模型更快（推理优化）")])]),v._v(" "),r("p",[v._v("例如，融合操作，分布计算，优化内存占用，编写针对特定硬件的高性能内核，等等。")]),v._v(" "),r("ol",{attrs:{start:"2"}},[r("li",[v._v("使模型更小（模型压缩）")])]),v._v(" "),r("p",[v._v("最初，这个系列的技术是使模型更小，以使它们适合边缘设备。使模型变小通常会使它们运行得更快。例如，用16位浮点数（半精度）或8位整数（定点）代替32位浮点数（全精度）来表示你的模型权重。在极端情况下，有些人尝试用1位表示（二进制权重神经网络），例如"),r("a",{attrs:{href:"https://arxiv.org/abs/1511.00363",target:"_blank",rel:"noopener noreferrer"}},[v._v("BinaryConnect"),r("OutboundLink")],1),v._v("和"),r("a",{attrs:{href:"https://arxiv.org/abs/1603.05279",target:"_blank",rel:"noopener noreferrer"}},[v._v("Xnor-Net"),r("OutboundLink")],1),v._v("。Xnor-Net的作者从Xnor.ai分拆出来，这是一家专注于模型压缩的创业公司，"),r("a",{attrs:{href:"https://www.geekwire.com/2020/exclusive-apple-acquires-xnor-ai-edge-ai-spin-paul-allens-ai2-price-200m-range/",target:"_blank",rel:"noopener noreferrer"}},[v._v("据说被苹果公司以2亿美元收购。"),r("OutboundLink")],1),v._v("\n不过这种技术通常出现在CV、NLP等领域比较常用。")]),v._v(" "),r("ol",{attrs:{start:"3"}},[r("li",[v._v("让硬件更快")])]),v._v(" "),r("p",[v._v("这是另一个正在蓬勃发展的研究领域。国内外的大厂和初创公司都在竞相开发硬件，使大型ML模型能够在云端，尤其是在设备上更快地进行推理，甚至训练。")]),v._v(" "),r("h4",{attrs:{id:"实时管道"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#实时管道"}},[v._v("#")]),v._v(" 实时管道")]),v._v(" "),r("h4",{attrs:{id:"事件驱动与请求驱动"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#事件驱动与请求驱动"}},[v._v("#")]),v._v(" 事件驱动与请求驱动")]),v._v(" "),r("p",[v._v("在过去的十年中，软件世界已经走向了微服务。这个做法是把你的业务逻辑分解成小的组件——每个组件都是一个独立的服务——可以独立维护。每个组件的所有者可以快速更新和测试该组件，而不必访问系统的其他部分。")]),v._v(" "),r("p",[v._v("微服务通常与REST结伴出现，REST是一套让这些微服务进行通信的方法。REST APIs是请求驱动的。客户端（服务）通过POST和GET等方法发送请求，告诉它的Server到底要做什么，而它的Server会对结果做出回应。Server必须监听请求，才能进行注册。因为在一个请求驱动的世界里，数据是通过对不同服务的请求来处理的，所以没有人对数据如何在整个系统中流动有一个总体的了解。考虑一个有3个服务的简单系统：")]),v._v(" "),r("ul",[r("li",[v._v("A管理司机的供应")]),v._v(" "),r("li",[v._v("B管理乘车需求")]),v._v(" "),r("li",[v._v("C预测客户每次要求乘车时的最佳价格。")])]),v._v(" "),r("p",[v._v("因为价格取决于供应和需求，服务C的输出取决于服务A和B的输出。C需要ping A和B进行预测，A需要ping B知道是否调动更多的司机，ping C知道给他们什么价格激励。第二，没有简单的方法来监测A或B的逻辑变化如何影响服务C的性能，或者在服务C的性能突然下降时映射数据流来进行调试。")]),v._v(" "),r("p",[v._v("只有3个服务，事情就已经很复杂了。想象一下，如果有成百上千的服务，就像大型互联网公司所拥有的那样。服务间的通信将是高负载的。在HTTP上以JSON blobs的形式发送数据——REST请求通常采用的方式，当然也很慢。服务间的数据传输会成为一个瓶颈，使整个系统变慢。")]),v._v(" "),r("p",[v._v("与其让20个服务向服务A索取数据，不如说每当服务A发生事件时，这个事件就会被广播到一个流中，哪个服务想要A的数据，就可以订阅这个流并挑选出它所需要的数据？如果有一个流，所有的服务都可以广播他们的事件并订阅，那会怎么样？这种模式被称为pub/sub：发布和订阅。这就是像Kafka这样的工具的处理方式。由于所有的数据都是通过一个流来流动的，你可以设置一个dashboard来监控你的数据和它在整个系统中的流转。因为它是基于服务所广播的事件，这种架构是事件驱动的。")]),v._v(" "),r("p",[v._v("总的来说，请求驱动架构对那些更多依赖逻辑而非数据的系统很有效。事件驱动架构对重数据的系统来说效果更好。")]),v._v(" "),r("h2",{attrs:{id:"level-2-持续学习-你的系统可以接收新数据并实时更新"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#level-2-持续学习-你的系统可以接收新数据并实时更新"}},[v._v("#")]),v._v(" level 2：持续学习——你的系统可以接收新数据并实时更新")]),v._v(" "),r("p",[v._v("这里的实时定义为分钟级的。当听到持续学习时，人们想象更新模型非常频繁，比如每5分钟一次。许多人认为大多数公司不需要如此频繁的更新，因为：")]),v._v(" "),r("ul",[r("li",[v._v("他们没有流量使该再训练计划有意义。")]),v._v(" "),r("li",[v._v("他们的模型不会衰减得那么快。")])]),v._v(" "),r("p",[v._v("这种说法对也不对，因为持续学习不是关于再训练的频率，而是模型被再训练的方式。")]),v._v(" "),r("blockquote",[r("p",[v._v("采用持续学习的好处是，与其根据一个固定的时间表或观察模型的在一段时间内的表现来更新你的模型，不如在数据分布发生变化和模型的性能急剧下降时不断地更新你的模型。")])]),v._v(" "),r("h3",{attrs:{id:"界定-持续学习"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#界定-持续学习"}},[v._v("#")]),v._v(" 界定“持续学习”")]),v._v(" "),r("p",[v._v("这里的“持续学习”，指的是系统可以实时接收用户反馈的数据点或微批量的数据样本进行动态更新模型。在一个数据点上运行学习步骤可能比在一个微批量样本上运行学习步骤更昂贵（高并发的场景可以通过拥有足够强大的硬件来处理一个数据点来缓解）。即使一个模型在每个传入的数据点上学习，也不意味着新的权重在每个数据点后被部署。在我们目前对ML算法如何学习的有限理解下，更新的模型需要首先被评估，看看它的表现如何。")]),v._v(" "),r("p",[v._v("对于大多数做所谓的在线训练或在线学习的公司来说，他们的模型都是在数据点累积到一定batch后在进行的学习，并在一定时间后进行评估。只有在其性能被评估为令人满意后，模型才会被更广泛地部署。据了解，在微博的机器学习团队，他们从学习到部署模型更新的迭代周期是10分钟。")]),v._v(" "),r("p",[v._v("大多数公司做的是无状态再训练——模型每次都是从头开始训练。而真正的持续学习意味着允许有状态的训练——模型在新数据上继续训练（模型权重微调）。")]),v._v(" "),r("blockquote",[r("p",[v._v("一旦你的基础设施被设置为做有状态的训练，训练频率只是一个可以自定义的频次。你可以每小时更新一次模型，每天一次，或者每当你的系统检测到分布变化时，即可以更新你的模型。")])]),v._v(" "),r("p",[r("strong",[v._v("！需要注意的是")]),v._v("，持续学习框架中有状态训练指的是数据迭代。如果您更改模型架构或添加新特征，您仍然需要从头开始训练新模型。")]),v._v(" "),r("p",[v._v("有状态的再训练允许你用更少的数据更新你的模型。如果您每月更新一次模型，您可能需要根据过去3个月的数据从头开始重新训练模型。但是，如果您每天都更新您的模型，您只需要根据前一天的数据微调您的模型。对于每个数据点都要更新模型的场景，要求会高很多，您的服务需要更高频率的加载最新模型，同时需要将用户的实时反馈事件与服务加载的模型进行动态连接和训练。持续学习的另一个好特性是您最多只需要查看每个数据样本两次：一次在预测期间，一次在模型训练期间。如果您担心数据隐私，您可以在使用数据样本后丢弃它们。")]),v._v(" "),r("div",{attrs:{align:"center"}},[r("img",{attrs:{src:"/stratefull_train.png",width:"85%"}})]),v._v(" "),r("center",[v._v("无状态与有状态训练")]),v._v(" "),r("h3",{attrs:{id:"应用案例-2"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#应用案例-2"}},[v._v("#")]),v._v(" 应用案例")]),v._v(" "),r("p",[v._v("我们熟知的TikTok是很容易成瘾的app。它的秘密在于它的推荐系统能够快速学习你的偏好，并推荐你接下来可能会观看的视频，给用户带来难以置信的滚动体验，当然这在持续学习的系统面前这是可行的，因为TikTok背后的公司ByteDance已经建立了一个成熟的基础设施，使他们的推荐系统能够实时学习用户的喜好（用他们的行话说是“用户标签”）。")]),v._v(" "),r("p",[v._v("推荐系统是持续学习的完美场景。它们有自然的标签——如果一个用户点击了一个推荐，那就是一个正确的预测。当然并非所有的推荐系统都需要持续的学习， 比如用户对房屋、汽车、航班、酒店等物品的偏好不太可能从一分钟到下一分钟发生变化，所以系统持续学习的意义不大。然而，用户对在线内容——视频、文章、新闻、推特、帖子、备忘录的偏好可能变化非常快。由于对在线内容的偏好是实时变化的，广告系统也需要实时更新以显示相关的广告。")]),v._v(" "),r("p",[v._v("持续的学习对于系统适应突发事件至关重要。考虑一下”双十一“网上购物。因为”双十一“每年只发生一次，某宝或其他电子商务网站不可能获得足够的历史数据来了解用户在那一天的行为，所以他们的系统需要在那一天不断地学习以适应。")]),v._v(" "),r("p",[v._v("持续学习在需要边缘部署的场景也非常有效，当你把持续学习和边缘部署结合起来的时候。想象一下，你可以将一个基础模型与一个新的设备——手机、手表、无人机等一起发布，该设备上的模型将不断地更新并适应其环境。没有集中的服务器成本，不需要在设备和云之间来回传输数据。")]),v._v(" "),r("p",[v._v("此外，持续的学习也可以帮助解决冷启动问题。一个用户刚刚加入你的应用程序，你还没有他们的信息。如果你没有任何形式的持续学习的能力，你将不得不为你的用户提供一般的推荐，直到下一次你的模型启动离线训练时。")]),v._v(" "),r("blockquote",[r("p",[v._v("Grubhub 在从无状态每日再训练切换到有状态每日再训练后，将训练成本降低了"),r("a",{attrs:{href:"https://arxiv.org/abs/2107.07106",target:"_blank",rel:"noopener noreferrer"}},[v._v("45倍"),r("OutboundLink")],1),v._v("（2021 年）。")])]),v._v(" "),r("h3",{attrs:{id:"解决方案-2"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#解决方案-2"}},[v._v("#")]),v._v(" 解决方案")]),v._v(" "),r("p",[v._v("由于持续学习仍然相当新，而且大多数正在做的公司还没有公开开源或讨论它的细节，所以没有标准的解决方案。")]),v._v(" "),r("p",[v._v("持续学习并不意味着“没有批量训练”。那些最成功地使用持续学习的公司也在离线情况下并行训练他们的模型，然后将在线版本与离线版本结合起来。")]),v._v(" "),r("h3",{attrs:{id:"挑战"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#挑战"}},[v._v("#")]),v._v(" 挑战")]),v._v(" "),r("p",[v._v("持续学习面临许多挑战，包括理论和实践。")]),v._v(" "),r("h4",{attrs:{id:"理论方面"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#理论方面"}},[v._v("#")]),v._v(" 理论方面")]),v._v(" "),r("p",[v._v("持续学习把我们所学到的很多关于机器学习的知识都颠覆了。在机器学习的入门课上，学生们可能会被教导不同版本的“用足够数量的历时来训练你的模型直到收敛”。在持续学习中，没有epoch——你的模型对每个数据点只看一次。也没有所谓的收敛。你的基础数据分布一直在变化。没有什么固定的东西可以收敛。")]),v._v(" "),r("p",[v._v("持续学习的另一个理论挑战是模型评估。在传统的批量训练中，你在固定的测试集上评估你的模型。如果一个新的模型在相同的测试集上比现有的模型表现得更好，我们就说新的模型更好。然而，持续学习的目标是让你的模型适应不断变化的数据。如果你更新的模型是为了适应现在的数据而训练的，而我们知道现在的数据与过去的数据不同，那么用旧的数据来测试你更新的模型就没有意义了。")]),v._v(" "),r("p",[v._v("那么我们怎么知道根据过去10分钟的数据训练的模型比根据20分钟前的数据训练的模型更好呢？我们必须在当前数据上比较这两个模型。在线训练需要在线评估，但把一个没有经过测试的模型提供给用户，听起来是一件挺有风险的事。")]),v._v(" "),r("p",[v._v("许多公司还是这样做了。新的模型首先要接受离线测试，以确保它们不是灾难性的，然后通过一个复杂的A/B测试系统与现有的模型同时进行在线评估。只有当一个模型被证明在公司关心的某些指标上优于现有模型时，它才能被更广泛地部署。(不要让一开始就为在线评估选择一个指标）。")]),v._v(" "),r("h4",{attrs:{id:"实践"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#实践"}},[v._v("#")]),v._v(" 实践")]),v._v(" "),r("p",[v._v("目前还没有在线训练的标准基础设施。一些公司已经趋向于使用参数服务器的流媒体架构，但除此之外，我所接触过的做在线训练的公司都必须在内部建立大量的基础设施。")]),v._v(" "),r("p",[v._v("此外，在这个阶段你需要的主要是一个更好的模型存储。")]),v._v(" "),r("ul",[r("li",[v._v("模型血统：你不仅要对你的模型进行版本管理，还要跟踪它们的脉络——哪个模型对哪些参数进行微调。")]),v._v(" "),r("li",[v._v("流特征的可重现性：你希望能够通过时间戳来提取过去的流特征，并在过去的任何时候为你的模型重新创建训练数据，以防发生什么事情，你需要进行调试。")])]),v._v(" "),r("p",[v._v("据我所知，没有一个现成的模型存储具有这两种能力。你也许可以将流式特征的可重现性委托给一个特征存储库（feature store），但你很可能必须在内部建立这个解决方案。")]),v._v(" "),r("blockquote",[r("p",[r("strong",[v._v("tips")]),v._v("：记录和等待（特征重用）\n当你在新的数据上重新训练你的模型时，很可能新的数据已经经过了你的预测服务，这意味着已经为预测提取了一次特征。很多公司将这些提取的特征重新用于模型更新，这既节省了计算量，又能使预测和训练之间保持一致。这种方法被称为记录和等待。这是一个经典的方法，可以减少训练服务的偏差（由生产环境和开发环境不匹配造成的错误）。\n这还不是一个流行的方法，但它正变得越来越流行。我预计它很快就会成为一种标准。"),r("a",{attrs:{href:"https://craft.faire.com/building-faires-new-marketplace-ranking-infrastructure-a53bf938aba0",target:"_blank",rel:"noopener noreferrer"}},[v._v("Faire有一篇很好的博文"),r("OutboundLink")],1),v._v("，讨论了他们的日志和等待方法的优点和缺点。")])]),v._v(" "),r("h2",{attrs:{id:"总结"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[v._v("#")]),v._v(" 总结")]),v._v(" "),r("p",[v._v("无论你是否准备好，机器学习的发展趋势都是在向实时前进。虽然大多数公司还在争论在线推理和持续学习是否有价值，但一些做得正确的公司已经看到了投资回报，他们的实时算法可能是帮助他们领先于竞争对手的一个主要因素。")]),v._v(" "),r("p",[v._v("实时ML在很大程度上是一个基础设施问题。要解决这个问题，需要数据科学/ML团队和平台团队共同合作。在线推理和持续学习都需要一个成熟的基础设施。持续学习的训练部分可以在批处理中完成，但在线评估部分需要流数据。")])],1)}),[],!1,null,null,null);r.default=a.exports}}]);